{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae80da9",
   "metadata": {},
   "source": [
    "# Mouse management using OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f177cfe",
   "metadata": {},
   "source": [
    "This Jupyter Notebook executes a scritp that will allow you to move the cursor to the position your eyes are pointing at. By implementing an alternatve to mouse management that optimices daily work and modernizes the use of the conventional mouse, our productivity will be increased when developing.\n",
    "#### Before you start!\n",
    "- Notice that bad illumination will make a huge difference on the output due to the cascade model mistakes during the face detection process. \n",
    "- You should also have a good posture facing the camera since the model does not recognize a side-way face. Take a look at the expected results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c7fec9",
   "metadata": {},
   "source": [
    "<img src=\"./images/demo.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c091a",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>1. Libraries and pre-trained models imports.</i></b></span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810ab8a",
   "metadata": {},
   "source": [
    "The core library for this project is **OpenCV** since it will be responsable of processing each frame of the input  and make the corresponding transformations. Our program needs to be able to detect faces and eyes since the movement of the pupils are the responsable of the displacement of the mouse.\n",
    "With that intention, by importing the open source **cascades** provided by OpenCV we will have two pre-trained models at our disposal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc2c4ce",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b><i>Attention! </i></b></span>You will have to install the libray **pynput** to run it locally on your compute. Otherwise, the mouse handler won't be able to detect your clicks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed3c2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pynput.mouse import Button, Controller\n",
    "\n",
    "# We'll use the cascades from cv2 for face and eyes detecction\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Set the mouse handler\n",
    "mouse = Controller()\n",
    "# Var for pupil center\n",
    "center = None\n",
    "oldCenter = None\n",
    "\n",
    "# Open a window with the input video\n",
    "showResoults = 1 # Hide=0 and Show=1\n",
    "# Sets the camera port\n",
    "idxCamera = 0 # Default=0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f7a76",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>2. Main iteration loop.</i></b></span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724235c",
   "metadata": {},
   "source": [
    "Since we have stablish the bases that our application will need to properly work, now we are able of **analyze** each frame of the input video. In this particular case this input is provided by our connected camera, so the program must follow  this sequence of steps:\n",
    "\n",
    "-  First, the frame needs to be read from the camera and processed as grayscale for better detecction.\n",
    "-  Then, we'll need to focus on the user's face through the previously imported face cascade. Within this new section the program looks for the eyes.\n",
    "-  As before, the program will focus on the user's pupil within the eyes area. If more than two eyes are detected, only the most likely will be consider.\n",
    "-  Applying the HoughCircles method we can detect the pupils with decent precission.\n",
    "-  Calculing the difference between the center of consecutive frames we can determine how much the mouse pointer needs to be moved from its  position. \n",
    "- Last step is to check if the user has already press any click button. If so, use the controller provided by pynput to make the action.\n",
    "\n",
    "<span style=\"color:red\"><b><i>Attention! </i></b></span>Note that the program stops when the user presses the '**ESC**' key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84e2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to open the camera at idxCamera\n",
    "capture = cv2.VideoCapture(idxCamera)\n",
    "if not capture.isOpened(): \n",
    "    print('Camera could not be detected. Please try changing the port.')\n",
    "    \n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect the face\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw the rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 5)\n",
    "        roi_gray = gray[y:y+w, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "       \n",
    "        # Detect the eyes\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.3, 5)\n",
    "        # Only detect two eyes per face\n",
    "        if len(eyes) > 2: continue \n",
    "        for (ex, ey, ew, eh) in eyes:               \n",
    "            # Draw the rectangle around the eyes\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 4)\n",
    "            eyes_gray = roi_gray[ey:ey+ew, ex:ex+ew]\n",
    "            eyes_color = roi_color[ey:ey+eh, ex:ex+ew]\n",
    "            \n",
    "            # Detect the pupil of the eyes\n",
    "            circles = cv2.HoughCircles(eyes_gray, cv2.HOUGH_GRADIENT,1, ey/8, param1=400,param2=15,minRadius=int(ex/8),maxRadius=int(ex/3))\n",
    "            if circles is not None:\n",
    "                circles = np.uint16(np.around(circles))\n",
    "                # only get one eye for mouse movement\n",
    "                for i in circles[0]:\n",
    "                    if len(circles) > 2: continue\n",
    "                  # get the center of the circle\n",
    "                    center = (i[0], i[1])\n",
    "                  # draw the outer circle\n",
    "                    cv2.circle(eyes_color,center,i[2],(0,255,0),1, 2)\n",
    "                  # draw the center of the circle\n",
    "                    cv2.circle(eyes_color,center,2,(0,0,255),3)\n",
    "                    \n",
    "                    # Calculate the mouse displacement\n",
    "                    if oldCenter is not None:\n",
    "                      displacement = (center[0] - oldCenter[0], center[1] - oldCenter[1])\n",
    "                      if (displacement[0] < 10 and displacement[1] < 10):\n",
    "                          mouse.move(displacement[0], displacement[1])\n",
    "                    oldCenter = center\n",
    "                    \n",
    "    \n",
    "    \n",
    "    # Loop ends when pressing 'ESC'\n",
    "    key = cv2.waitKey(20)\n",
    "    if key == 27: \n",
    "        break\n",
    "    if key == ord('q'):\n",
    "      mouse.click(Button.left,1)\n",
    "    if key == ord('e'):\n",
    "      mouse.click(Button.right,1)\n",
    "    \n",
    "    # Controls the window display\n",
    "    if (showResoults):\n",
    "        cv2.imshow('Demo', frame)\n",
    "        \n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ab8b06",
   "metadata": {},
   "source": [
    "### Conclusions and project improvements.\n",
    "The hardest aspect is definitly **pupil traking**. Since our eyes are constantly moving and its displacement is very small, the HoughCircles() funtion is not precise enough. This ocasionates difficulties on the **mouse interactions** due to abrupt changes in the cursor position. An interesting way to improve this project could be change parameters values in search of an combination that correctly works. If it's not possible, maybe we should find another library."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
